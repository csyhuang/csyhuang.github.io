I"R<h2 id="sparks-toolkit">Spark’s toolkit</h2>
<table style="border-collapse: collapse; min-width: 100%;"><colgroup><col style="width: 130px;" /><col style="width: 130px;" /><col style="width: 130px;" /></colgroup>
	<tbody>
		<tr>
		<td style="width: 130px; padding: 8px; border: 1px solid;">
		<div style="text-align: center; ">Structured Streaming</div>
		</td>
		<td style="width: 130px; padding: 8px; border: 1px solid;">
		<div style="text-align: center; ">Advanced Analytics</div>
		</td>
		<td style="width: 130px; padding: 8px; border: 1px solid;">
		<div style="text-align: center; ">Libraries &amp; Ecosystem</div>
		</td>
		</tr>
		<tr>
		<td colspan="3" style="width: 390px; padding: 8px; border: 1px solid;">
		<div style="text-align: center; ">Structured API</div>
		<div style="text-align: center; ">Datasets, DataFrames, SQL</div>
		</td>
		</tr>
		<tr>
		<td colspan="3" style="width: 390px; padding: 8px; border: 1px solid;">
		<div style="text-align: center; ">Low-level APIs</div>
		<div style="text-align: center; ">RDD, Distributed Variables</div>
		</td>
		</tr>
	</tbody>
</table>
<!--more-->

<h2 id="unified-aspect-of-spark">Unified aspect of Spark:</h2>
<ul>
  <li>Consistent, compassable APIs</li>
  <li>Unified engine for parallel data processing</li>
  <li>“Structured APIs” (Datasets, DataFrames, SQL)</li>
</ul>

<h2 id="computing-engines">Computing engines:</h2>
<ul>
  <li>Azure Storage and Amazon S3</li>
  <li>Distributed file systems (e.g. Apache Hadoop)</li>
  <li>Key-value stores (e.g. Apache Cassandra)</li>
  <li>Message buses (e.g. Apache Kafka)
Spark focuses on performing computations over the data, no matter where it resides.</li>
</ul>

<h2 id="hadoop">Hadoop:</h2>
<ul>
  <li>Storage system: the Hadoop file system/HDFS designed for low-cost stage over clusters of commodity servers</li>
  <li>Computing system: MapReduce
Environments for which Hadoop architecture cannot work: public cloud/streaming application -&gt; Spark can work on that too</li>
</ul>

<h2 id="libraries">Libraries:</h2>
<ul>
  <li>SQL</li>
  <li>Structured data (Spark SQL)</li>
  <li>Machine learning (MLlib)</li>
  <li>Stream processing (Spark Streaming and newer Structured Streaming)</li>
  <li>Graph analysis (GraphX)</li>
</ul>

<h2 id="context-the-big-data-problem">Context: the big data problem</h2>
<ul>
  <li>Hardware advancement: (before 2005) computer became faster every year through processor speed increase</li>
  <li>The trend in hardware stopped around 2005 due to hard limit in heat dissipation</li>
  <li>Developer switch towards adding more parallel CPU cores all running at the same speed</li>
  <li>The cost to store 1TB of data continues to drop by roughly two times every 14 months</li>
  <li>Collecting data is extremely inexpensive</li>
  <li>Processing huge amount of data requires large, parallel computation, often on clusters of machines</li>
</ul>

<h2 id="running-spark">Running Spark</h2>
<ul>
  <li>Spark can be used from Python, Java, Scala, R, or SQL</li>
  <li>Spark is written in Scala, and runs on the Java Virtual Machine (JVM)</li>
  <li>To run Spark, one has to install Java</li>
</ul>
:ET