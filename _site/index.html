<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Blog &middot; Clare S. Y. Huang
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/lanyon.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>PhD in Geophysical Sciences (UChicago). Love coding, music and writing.</p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="/">Home</a>
    <a class="sidebar-nav-item" href="/about_me.html" >About me</a>    

    

    
    
      
        
      
    
      
        
      
    
      
        
      
    
      
    
      
        
          <a class="sidebar-nav-item" href="/bookshelf/">Bookshelf</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/climate_tools/">Climate Analysis Tools</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/ds_notes/">Study Notes</a>
        
      
    
      
    
      
        
          <a class="sidebar-nav-item" href="/musicarrangement/">Music Arrangements</a>
        
      
    
      
        
      
    
      
        
      
    
      
        
          <a class="sidebar-nav-item" href="/publications/">Publications</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/pyspark_solutions/">PySpark/SQL Solutions</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/research/">Academic Research</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/tools/">Handy Tools</a>
        
      
    

<!--    <a class="sidebar-nav-item" href="/archive/v1.0.0.zip">Download</a> -->

    <a class="sidebar-nav-item" href="http://github.com/csyhuang/"  target="_blank">Github</a>
<!--    <span class="sidebar-nav-item">Currently v1.0.0</span> --->
  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2021 Shao Ying (Clare) Huang. All rights reserved.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/" title="Home">Clare S. Y. Huang</a>
            <small>Data Scientist | Atmospheric Dynamicist</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<div class="row">
  <div class="col-sm-8">
<!-- 
  <p class="influidcontainer">I have just completed my Ph.D degree in Geophysical Sciences in the University of Chicago and currently work as a postdoctoral research assistant in Professor Noboru Nakamura's group.
  My <a href="/research">dissertation</a> focuses on developing an atmospheric Rossby wave diagnostic theory that quantifies the severity of extreme weather events. I am now working on the search of predictive features of atmospheric blocking using the local wave activity theory I developed and some machine learning techniques.
  Check out my <a href="https://github.com/csyhuang/hn2016_falwa" target="blank">python library</a> to implement this diagnosis on climate data!
  </p>
  <p class="influidcontainer">
  I also participated in the <a href="http://insightdatascience.com">Insight Data Science Fellowship Program</a> in 2017 summer as a Health Data Fellow to learn about data science and health industry.
  Currently, I work in the Research Analytics team at <a href="http://tempus.com/">Tempus</a>.
  </p>
 -->
  <p class="influidcontainer">
  I love to share what I've learnt with others. Check out my blog posts and notes about my 
  academic research, as well as technical solutions on software engineering and data 
  science challenges.
  </p>  
  </div>
  

  <div class="col-sm-4">
<!-- 

    <img src="/assets/img/profile_pic_square.jpg">
    
 -->
    <div align="right">
      <p><a href="http://csyhuang.github.io/feed.xml"  target="_blank"><i class="fa fa-rss" aria-hidden="true"></i> RSS Feed </a></p>
      <p><a href="mailto:csyhuang@uchicago.edu"><i class="fa fa-envelope" aria-hidden="true"></i> Email </a></p>
    </div>
    
    
  </div>
</div>


<!-- 
Welcome to my personal homepage! Please use the <b>left-side menu</b> to navigate to pages related to my academic work. This index page is maintained in a blog-like manner that I'll constantly put in things I've learnt, and updated content of this website.
  </div>
</div>
 -->
<div class="clear"></div>
<hr>

<div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2021/05/22/contrastive-learning/">
        Discussion on Contrastive Learning
      </a>
    </h1>

    <span class="post-date">22 May 2021</span>

    
        <div>
            <p>I am leading the Machine Learning Journal Club discussion on the two papers:</p>
<ul>
  <li>Wang, G., Wang, K., Wang, G., Torr, P. H., &amp; Lin, L. (2021). <a href="https://arxiv.org/abs/2104.08760">Towards Solving Inefficiency of Self-supervised Representation Learning.</a> arXiv preprint arXiv:2104.08760.</li>
  <li>Chen, T., Kornblith, S., Norouzi, M., &amp; Hinton, G. (2020, November). <a href="https://arxiv.org/abs/2002.05709">A simple framework for contrastive learning of visual representations.</a> In International conference on machine learning (pp. 1597-1607). PMLR.</li>
</ul>


        </div>
        <input type="checkbox" class="read-more-state" id="/2021/05/22/contrastive-learning/"/>
        <div class="read-more">
            

<p>You can find <a href="https://docs.google.com/presentation/d/1ZS-L-o46h68Q78UR-7nCCRZls4a53M6L_73CHr6xFN4/edit?usp=sharing">here</a> the slides I made which provides an introduction to Contrastive Learning. Below are the main points from the slides:</p>
<ul>
  <li>Contrastive learning is a self-supervised method to learn a representation of objects by maximizing/minimizing distance between the same/different class(es)</li>
  <li>Contrastive learning benefits from data augmentation and increase in model parameters</li>
  <li>Under-clustering occurs when there is not enough negative samples to learn from; over-clustering occurs when the model overfits (memorize the data)</li>
  <li>To solve inefficiency issue, median(rank-k) triplet loss is used instead of the total loss</li>
</ul>


        </div>
        <label for="/2021/05/22/contrastive-learning/" class="read-more-trigger"></label>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2021/01/13/finished-gans-specialization/">
        I finished the GANs Specialization on Coursera!
      </a>
    </h1>

    <span class="post-date">13 Jan 2021</span>

    
        <div>
            <p>I finished the <a href="https://www.coursera.org/specializations/generative-adversarial-networks-gans">3-course Generative Adversarial Networks (GANs) Specialization</a> on Coursera! It was super fun! Here are <a href="https://docs.google.com/presentation/d/1_oI408zCyrn8jNsR3-gUBiKhD73rqFnKtRI6h5eFs9A/edit?usp=sharing">some slides</a> I presented in a deep learning journal club with my peers, which is a survey of GANs covered in this Specialization.</p>


        </div>
        <input type="checkbox" class="read-more-state" id="/2021/01/13/finished-gans-specialization/"/>
        <div class="read-more">
            
<p>Click <a href="https://coursera.org/share/08ef512d600b5edf936febb0f24ed034">here</a> to view my certificate. üò¨</p>

        </div>
        <label for="/2021/01/13/finished-gans-specialization/" class="read-more-trigger"></label>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2020/12/26/added-page-music-arrangement/">
        Added a directory for some of my music arrangements
      </a>
    </h1>

    <span class="post-date">26 Dec 2020</span>

    
        <p>üéπ I have been uploading improvised piano cover on my YouTube channel. Recently, I received some comments asking for the music sheet of my arrangement, and it seems to be a good idea to keep a record of my work. Therefore, I started making music sheets of my arrangement with <a href="https://musescore.org/">MuseScore</a> to share with others.</p>

<p>üéº Check out the page <a href="/musicarrangement/">Music Arrangement</a> for the collection of arrangement with music sheets I‚Äôve made. For the rest of my recordings, go to my YouTube Channel <a href="https://youtube.com/phyclare">Clare‚Äôs Studio</a>.</p>

    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2020/12/10/databricks-certified-associate-developer-exam-spark-3/">
        Databricks Certified Associate Developer for Apache Spark 3.0
      </a>
    </h1>

    <span class="post-date">10 Dec 2020</span>

    
        <p>I passed the <strong>Databricks Certified Associate Developer exam for Apache Spark 3.0 (python)</strong>. Here is <a href="https://academy.databricks.com/award/certification/9099bdd0-4245-3b63-8265-fc234ef098f6/view">my certificate</a>!</p>

<p>I registered for the exam when joining the Spark Summit this June, hoping to set a goal to push myself to dive deeper into spark architecture and performance tuning.</p>

<p>[Experience sharing] On top of coding with pyspark at work (which helps me with most of the syntax questions in the exam), my exam preparation mainly involves reading the two books, <a href="https://www.oreilly.com/library/view/spark-the-definitive/9781491912201/">Spark: The Definitive Guide</a> and <a href="https://databricks.com/p/ebook/learning-spark-from-oreilly">Learning Spark 2.0</a>.</p>

<p>It was my very first time taking an online proctored exam at home, and there were two things I wish I could have known before the exam:</p>
<ol>
  <li>The spark documentation (PDF file) provided by Sentinel (i.e., the exam software) is not searchable. One has to scroll through the page to find what s/he needs.</li>
  <li>The proctor would check your workspace configuration during the exam (i.e., not at the beginning). The exam would pause during the check, so you don‚Äôt have to worry about losing time.</li>
</ol>

<p>I believe there will be more tests conducted with an online proctor given the evolution of the pandemic. Perhaps we will get used to the online test workspace setup at home very soon.</p>

    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2020/11/14/deep-compression/">
        Discussion on Deep Compression
      </a>
    </h1>

    <span class="post-date">14 Nov 2020</span>

    
        <p>I was leading a discussion on the paper Han, S., Mao, H., &amp; Dally, W. J. (2015). <a href="https://arxiv.org/abs/1510.00149">Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding</a>. arXiv preprint arXiv:1510.00149. It introduces the methods to reduce the storage requirement of neural networks such that it can be stored on smaller devices.</p>

<p>The slides I made for the discussion can be found <a href="https://docs.google.com/presentation/d/1I-NutRXf15iWKEDOmEHgxht5n9m7k5ZeQHivspHYSAw/edit?usp=sharing">here</a>.</p>

    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2020/10/29/odsc-west-talk-on-mlops/">
        Notes on ModelOps and MLOps talks
      </a>
    </h1>

    <span class="post-date">29 Oct 2020</span>

    
        <p>I wrote a short article on Medium, <a href="https://claresyhuang.medium.com/odsc-west-2020-notes-on-modelops-and-mlops-talks-a2e0d10f3c46">ODSC West 2020: Notes on ModelOps and MLOps talks</a>, about what I learned from two talks in ODSC West 2020.</p>


    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2020/10/07/unittest-notes/">
        Running a single test case in the unittest suite
      </a>
    </h1>

    <span class="post-date">07 Oct 2020</span>

    
        <p>If your unit tests are written using the <code class="language-plaintext highlighter-rouge">unittest</code> package, to run a <em>single</em> test case in the TestSuite, the command line syntax is</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python setup.py <span class="nb">test</span> <span class="nt">-m</span> tests.test_module.TestClass.test_case
</code></pre></div></div>

<p>Stack Overflow reference: <a href="https://stackoverflow.com/questions/21167516/does-unittest-allow-single-case-suite-testing-through-setup-py-test">Does unittest allow single case/suite testing through ‚Äúsetup.py test‚Äù?</a></p>

<p>If your unit tests are written using <code class="language-plaintext highlighter-rouge">pytest</code>, the command used would be</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pytest tests/test_module.py::test_case
</code></pre></div></div>

    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2020/10/03/update-in-pip-in-october/">
        New pip release and changes in its way to resolve dependency conflicts
      </a>
    </h1>

    <span class="post-date">03 Oct 2020</span>

    
        <p>When I was trying to set up a conda environment to run a package‚Ä¶</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.

We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.

numpydoc 1.1.0 requires sphinx&gt;=1.6.5, but you'll have sphinx 1.5.3 which is incompatible.
</code></pre></div></div>

<p>After googling, I found <a href="https://stackoverflow.com/questions/63277123/what-is-use-feature-2020-resolver-error-message-with-jupyter-installation-on">this post on StackOverflow</a> explaining the issue - it is related to the changes in <a href="https://discuss.python.org/t/announcement-pip-20-2-release/4863">pip‚Äôs release 20.2</a>.</p>

<p>To implement the check, install packages with the command</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install</span> <span class="nt">--use-feature</span><span class="o">=</span>2020-resolver package
</code></pre></div></div>

    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2020/10/03/pull-request-from-forked-repo/">
        Submitting pull request from forked repo to main repo
      </a>
    </h1>

    <span class="post-date">03 Oct 2020</span>

    
        <p>It‚Äôs <a href="https://hacktoberfest.digitalocean.com/">HacktoberFest</a> again! üëª Here are some useful commands to merge your forked repo with upstream changes from the original repo (Also see <a href="https://docs.github.com/en/free-pro-team@latest/github/collaborating-with-issues-and-pull-requests/syncing-a-fork">GitHub Docs</a>).</p>

<p>After forking, specify remote upstream repository:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git remote add upstream https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git
</code></pre></div></div>

<p>You can then check the upstream locations via the command <code class="language-plaintext highlighter-rouge">git remote -v</code>.</p>

<p>Before submitting a pull request, you have to make sure your branch contains all the commits from upstream. You can do so by:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git fetch upstream
git checkout master
git merge upstream/master
</code></pre></div></div>

<p>ü§ì Have fun coding! ‚å®Ô∏è</p>

    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2020/09/17/split-vector-to-columns/">
        Split a vector/list in a pyspark DataFrame into columns
      </a>
    </h1>

    <span class="post-date">17 Sep 2020</span>

    
        <div>
            
        </div>
        <input type="checkbox" class="read-more-state" id="/2020/09/17/split-vector-to-columns/"/>
        <div class="read-more">
            

<h2 id="split-an-array-column">Split an array column</h2>
<p>To split a column with arrays of strings, e.g. a DataFrame that looks like,</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+---------+
|   strCol|
+---------+
|[A, B, C]|
+---------+
</code></pre></div></div>
<p>into separate columns, the following code without the use of UDF works.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pyspark.sql.functions</span> <span class="k">as</span> <span class="n">F</span>

<span class="n">df2</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">select</span><span class="p">([</span><span class="n">F</span><span class="p">.</span><span class="n">col</span><span class="p">(</span><span class="s">"strCol"</span><span class="p">)[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)])</span>
<span class="n">df2</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p>Output:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+---------+---------+---------+
|strCol[0]|strCol[1]|strCol[2]|
+---------+---------+---------+
|        A|        B|        C|
+---------+---------+---------+
</code></pre></div></div>

<h2 id="split-a-vector-column">Split a vector column</h2>
<p>To split a column with doubles stored in DenseVector format, e.g. a DataFrame that looks like,</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-------------+
|       intCol|
+-------------+
|[2.0,3.0,4.0]|
+-------------+
</code></pre></div></div>
<p>one have to construct a UDF that does the convertion of DenseVector to array(python list) first:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pyspark.sql.functions</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">ArrayType</span><span class="p">,</span> <span class="n">DoubleType</span>

<span class="k">def</span> <span class="nf">split_array_to_list</span><span class="p">(</span><span class="n">col</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">to_list</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">v</span><span class="p">.</span><span class="n">toArray</span><span class="p">().</span><span class="n">tolist</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">F</span><span class="p">.</span><span class="n">udf</span><span class="p">(</span><span class="n">to_list</span><span class="p">,</span> <span class="n">ArrayType</span><span class="p">(</span><span class="n">DoubleType</span><span class="p">()))(</span><span class="n">col</span><span class="p">)</span>

<span class="n">df3</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">split_array_to_list</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">col</span><span class="p">(</span><span class="s">"intCol"</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"split_int"</span><span class="p">))</span>\
    <span class="p">.</span><span class="n">select</span><span class="p">([</span><span class="n">F</span><span class="p">.</span><span class="n">col</span><span class="p">(</span><span class="s">"split_int"</span><span class="p">)[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)])</span>
<span class="n">df3</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p>Output:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+------------+------------+------------+
|split_int[0]|split_int[1]|split_int[2]|
+------------+------------+------------+
|         2.0|         3.0|         4.0|
+------------+------------+------------+
</code></pre></div></div>

        </div>
        <label for="/2020/09/17/split-vector-to-columns/" class="read-more-trigger"></label>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2020/09/14/dense-rank-and-character-order/">
        Ranking hierarchical labels with SQL
      </a>
    </h1>

    <span class="post-date">14 Sep 2020</span>

    
        <p>To give indices to hierarchical labels, I can use <code class="language-plaintext highlighter-rouge">DENSE_RANK()</code> or <code class="language-plaintext highlighter-rouge">RANK()</code> depending on the situation. 
For example, if I have a DataFrame that looks like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+------+----------+
|Fridge|    Fruits|
+------+----------+
|     A|     apple|
|     B|    orange|
|     C|     apple|
|     D|     pears|
|     C|Watermelon|
+------+----------+
</code></pre></div></div>

<p>The following SQL code</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span>
    <span class="n">Fridge</span><span class="p">,</span>
    <span class="n">Fruits</span><span class="p">,</span>
    <span class="n">DENSE_RANK</span><span class="p">()</span> <span class="n">OVER</span> <span class="p">(</span><span class="k">ORDER</span> <span class="k">BY</span> <span class="n">Fridge</span><span class="p">,</span> <span class="n">Fruits</span><span class="p">)</span> <span class="k">AS</span> <span class="n">Loc_id</span><span class="p">,</span>
    <span class="n">DENSE_RANK</span><span class="p">()</span> <span class="n">OVER</span> <span class="p">(</span><span class="k">ORDER</span> <span class="k">BY</span> <span class="n">Fridge</span><span class="p">)</span> <span class="k">AS</span> <span class="n">Fridge_id_dense</span><span class="p">,</span>
    <span class="n">RANK</span><span class="p">()</span> <span class="n">OVER</span> <span class="p">(</span><span class="k">ORDER</span> <span class="k">BY</span> <span class="n">Fridge</span><span class="p">)</span> <span class="k">AS</span> <span class="n">Fridge_id</span><span class="p">,</span>
    <span class="n">DENSE_RANK</span><span class="p">()</span> <span class="n">OVER</span> <span class="p">(</span><span class="k">ORDER</span> <span class="k">BY</span> <span class="n">Fruits</span><span class="p">)</span> <span class="k">AS</span> <span class="n">Fruit_id_dense</span><span class="p">,</span>
    <span class="n">RANK</span><span class="p">()</span> <span class="n">OVER</span> <span class="p">(</span><span class="k">ORDER</span> <span class="k">BY</span> <span class="n">Fruits</span><span class="p">)</span> <span class="k">AS</span> <span class="n">Fruit_id</span>
<span class="k">FROM</span> <span class="n">fridge_list</span>
</code></pre></div></div>

<p>would yield the following table</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+------+----------+------+---------------+---------+--------------+--------+
|Fridge|    Fruits|Loc_id|Fridge_id_dense|Fridge_id|Fruit_id_dense|Fruit_id|
+------+----------+------+---------------+---------+--------------+--------+
|     A|     apple|     1|              1|        1|             2|       2|
|     B|    orange|     2|              2|        2|             3|       4|
|     C|Watermelon|     3|              3|        3|             1|       1|
|     C|     apple|     4|              3|        3|             2|       2|
|     D|     pears|     5|              4|        5|             4|       5|
+------+----------+------+---------------+---------+--------------+--------+

</code></pre></div></div>

    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2020/08/01/custom-transformer/">
        Custom Transformer that can be fitted into Pipeline
      </a>
    </h1>

    <span class="post-date">01 Aug 2020</span>

    
        <div>
            <p>How to construct a custom Transformer that can be fitted into a Pipeline object? I learned from a colleague today how to do that.</p>

<p>Below is an example that includes all key components:

        </div>
        <input type="checkbox" class="read-more-state" id="/2020/08/01/custom-transformer/"/>
        <div class="read-more">
            </p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">pyspark</span> <span class="kn">import</span> <span class="n">keyword_only</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Transformer</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.param.shared</span> <span class="kn">import</span> <span class="n">HasInputCol</span><span class="p">,</span> <span class="n">HasOutputCol</span><span class="p">,</span> <span class="n">Param</span><span class="p">,</span> <span class="n">Params</span><span class="p">,</span> <span class="n">TypeConverters</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.util</span> <span class="kn">import</span> <span class="n">DefaultParamsReadable</span><span class="p">,</span> <span class="n">DefaultParamsWritable</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">DataFrame</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">StringType</span>
<span class="kn">import</span> <span class="nn">pyspark.sql.functions</span> <span class="k">as</span> <span class="n">F</span>

<span class="k">class</span> <span class="nc">CustomTransformer</span><span class="p">(</span><span class="n">Transformer</span><span class="p">,</span> <span class="n">HasInputCol</span><span class="p">,</span> <span class="n">HasOutputCol</span><span class="p">,</span> <span class="n">DefaultParamsReadable</span><span class="p">,</span> <span class="n">DefaultParamsWritable</span><span class="p">):</span>
  <span class="n">input_col</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="p">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s">"input_col"</span><span class="p">,</span> <span class="s">"input column name."</span><span class="p">,</span> <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="p">.</span><span class="n">toString</span><span class="p">)</span>
  <span class="n">output_col</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="p">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s">"output_col"</span><span class="p">,</span> <span class="s">"output column name."</span><span class="p">,</span> <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="p">.</span><span class="n">toString</span><span class="p">)</span>
  
  <span class="o">@</span><span class="n">keyword_only</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_col</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s">"input"</span><span class="p">,</span> <span class="n">output_col</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s">"output"</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">CustomTransformer</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">input_col</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">output_col</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
    <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_input_kwargs</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    
  <span class="o">@</span><span class="n">keyword_only</span>
  <span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_col</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s">"input"</span><span class="p">,</span> <span class="n">output_col</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s">"output"</span><span class="p">):</span>
    <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_input_kwargs</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    
  <span class="k">def</span> <span class="nf">get_input_col</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">input_col</span><span class="p">)</span>
  
  <span class="k">def</span> <span class="nf">get_output_col</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">output_col</span><span class="p">)</span>
  
  <span class="k">def</span> <span class="nf">_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">:</span> <span class="n">DataFrame</span><span class="p">):</span>
    <span class="n">input_col</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_input_col</span><span class="p">()</span>
    <span class="n">output_col</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_output_col</span><span class="p">()</span>
    <span class="c1"># The custom action: concatenate the integer form of the doubles from the Vector
</span>    <span class="n">transform_udf</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">udf</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s">'/'</span><span class="p">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">y</span><span class="p">))</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">x</span><span class="p">]),</span> <span class="n">StringType</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">df</span><span class="p">.</span><span class="n">withColumn</span><span class="p">(</span><span class="n">output_col</span><span class="p">,</span> <span class="n">transform_udf</span><span class="p">(</span><span class="n">input_col</span><span class="p">))</span>
  
</code></pre></div></div>

<p>Let‚Äôs test it with a dataframe</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>df = spark.createDataFrame([(Vectors.dense([2.0, 1.0, 3.0]),), (Vectors.dense([0.4, 0.9, 7.0]),)], ["numbers"])
</code></pre></div></div>
<p>and a Pipeline like this:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">ElementwiseProduct</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">elementwise_product</span> <span class="o">=</span> <span class="n">ElementwiseProduct</span><span class="p">(</span><span class="n">scalingVec</span><span class="o">=</span><span class="n">Vectors</span><span class="p">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">]),</span> <span class="n">inputCol</span><span class="o">=</span><span class="s">"numbers"</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s">"product"</span><span class="p">)</span>
<span class="n">custom_transformer</span> <span class="o">=</span> <span class="n">CustomTransformer</span><span class="p">(</span><span class="n">input_col</span><span class="o">=</span><span class="s">"product"</span><span class="p">,</span> <span class="n">output_col</span><span class="o">=</span><span class="s">"results"</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">elementwise_product</span><span class="p">,</span> <span class="n">custom_transformer</span><span class="p">])</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">results</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p>I manage to get the expected results:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-------------+--------------+-------+
|      numbers|       product|results|
+-------------+--------------+-------+
|[2.0,1.0,3.0]|[4.0,3.0,15.0]| 4/3/15|
|[0.4,0.9,7.0]|[0.8,2.7,35.0]| 0/2/35|
+-------------+--------------+-------+
</code></pre></div></div>

        </div>
        <label for="/2020/08/01/custom-transformer/" class="read-more-trigger"></label>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2020/07/14/hn2016_falwa-release0.4.1/">
        Minor release of my python package + release procedures
      </a>
    </h1>

    <span class="post-date">14 Jul 2020</span>

    
        <p>[<a href="https://github.com/csyhuang/hn2016_falwa/releases/tag/0.4.1">hn2016_falwa Release 0.4.1</a>] A minor release of my python package <a href="https://github.com/csyhuang/hn2016_falwa">hn2016_falwa</a> is published. Thanks <a href="https://github.com/chpolste">Christopher Polster</a> for submitting a pull request that fixes the interface of <code class="language-plaintext highlighter-rouge">BarotropicField</code>. Moreover, I added procedures to process masked array in <code class="language-plaintext highlighter-rouge">QGField</code> such that it can be conveniently used to process ERA5 data which is stored as masked array in netCDF files.</p>

<p>As a memo to myself - procedures for a release (which I often forget and have to google üòÖ):</p>
<ul>
  <li>Update version number in <code class="language-plaintext highlighter-rouge">setup.py</code>, <code class="language-plaintext highlighter-rouge">readme.md</code> and documentation pages.</li>
  <li>Add a (light-weighted) tag to the commit: <code class="language-plaintext highlighter-rouge">git tag &lt;tagname&gt;</code>.</li>
  <li>Not only push the commits but also the tag by <code class="language-plaintext highlighter-rouge">git push origin &lt;tagname&gt;</code>.</li>
</ul>

<p>If I have time, I would update the version on PYPI too:</p>
<ul>
  <li>Create the <code class="language-plaintext highlighter-rouge">dist/</code> directory and the installation files: <code class="language-plaintext highlighter-rouge">python3 setup.py sdist bdist_wheel</code></li>
  <li>Upload the package: <code class="language-plaintext highlighter-rouge">python3 -m twine upload --repository testpypi dist/*</code></li>
</ul>

    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2020/06/30/bulk-download-of-era5/">
        Bulk download of ERA5 data from CDSAPI
      </a>
    </h1>

    <span class="post-date">30 Jun 2020</span>

    
        <p>I wrote a sample script to download ERA5 reanalysis data via CDSAPI month by month. <a href="https://github.com/csyhuang/download_era5">Here is the GitHub repo</a> with instructions how to use it.</p>

    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2020/04/18/spark-definitive-guide-reading-note/">
        Reading Notes on Spark - The Definitive Guide
      </a>
    </h1>

    <span class="post-date">18 Apr 2020</span>

    
        <div>
            <p>I am reading the book <a href="https://www.oreilly.com/library/view/spark-the-definitive/9781491912201/">Spark: The Definitive Guide</a> by Bill Chambers, Matei Zaharia. Here are my reading notes:

        </div>
        <input type="checkbox" class="read-more-state" id="/2020/04/18/spark-definitive-guide-reading-note/"/>
        <div class="read-more">
            </p>

<ul>
  <li>
    <p><a href="/spark_the_def_guide/ch1">Ch.1 - What is Apache Spark?</a></p>
  </li>
  <li>
    <p><a href="/spark_the_def_guide/ch2">Ch.2 - A Gentle Introduction to Spark</a></p>
  </li>
  <li>
    <p><a href="/spark_the_def_guide/ch3">Ch.3 - A Tour of Spark‚Äôs Toolset</a></p>
  </li>
  <li>
    <p><a href="/spark_the_def_guide/ch4">Ch.4 - Structured API Overview</a></p>
  </li>
  <li>
    <p><a href="/spark_the_def_guide/ch5">Ch.5 - Basic Structured Operations</a></p>
  </li>
  <li>
    <p><a href="/spark_the_def_guide/ch6">Ch.6 - Working with different types of Data</a></p>
  </li>
  <li>
    <p><a href="/spark_the_def_guide/ch6-udf">Ch.6 - Working with different types of Data (UDFs)</a></p>
  </li>
  <li>
    <p><a href="/spark_the_def_guide/ch7">Ch.7 - Aggregations</a></p>
  </li>
</ul>


        </div>
        <label for="/2020/04/18/spark-definitive-guide-reading-note/" class="read-more-trigger"></label>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2020/04/17/add-read-more-on-front-page/">
        READ MORE button via jekyll
      </a>
    </h1>

    <span class="post-date">17 Apr 2020</span>

    
        <div>
            <p>Found a workable solution adding ‚Äúread more‚Äù button to jekyll posts from <a href="https://jonnylangefeld.com/blog/how-to-add-a-read-more-button-that-doesnt-suck-to-your-jekyll-blog">Jonny Langefeld‚Äôs blog post</a>. üòÑ Thanks for the solution!

        </div>
        <input type="checkbox" class="read-more-state" id="/2020/04/17/add-read-more-on-front-page/"/>
        <div class="read-more">
            
Here we go. üòâ</p>

        </div>
        <label for="/2020/04/17/add-read-more-on-front-page/" class="read-more-trigger"></label>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2020/04/16/faster-outer-join-by-two-left-joins/">
        More efficient way to do outer join with large dataframes
      </a>
    </h1>

    <span class="post-date">16 Apr 2020</span>

    
        <p>Today I learned from a colleague the way of doing <code class="language-plaintext highlighter-rouge">outer join</code> of large dataframes more efficiently: instead of doing the <code class="language-plaintext highlighter-rouge">outer join</code>, you can first <code class="language-plaintext highlighter-rouge">union</code> the key column, and then implement <code class="language-plaintext highlighter-rouge">left join</code> twice. I have done an experiment myself on the cluster with two dataframes (<code class="language-plaintext highlighter-rouge">df1</code> and <code class="language-plaintext highlighter-rouge">df2</code>) - each dataframe has ~10k rows, and there is only ~10% of overlap(i.e. an inner-join would result in ~1k rows).</p>

<p>The usual way of doing outer join would be like:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df3</span> <span class="o">=</span> <span class="n">df1</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">df2</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s">'outer'</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s">'id'</span><span class="p">).</span><span class="n">drop_duplicates</span><span class="p">()</span>
</code></pre></div></div>

<p>Here is an equivalent way(I call it <em>union-left</em> here) that takes less time to compute:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df3</span> <span class="o">=</span> <span class="n">df1</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">'id'</span><span class="p">).</span><span class="n">union</span><span class="p">(</span><span class="n">df2</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">'id'</span><span class="p">))</span>
<span class="n">df3</span> <span class="o">=</span> <span class="n">df3</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">x1_df</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s">'left'</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s">'id'</span><span class="p">)</span>
<span class="n">df3</span> <span class="o">=</span> <span class="n">df3</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">x2_df</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s">'left'</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s">'id'</span><span class="p">).</span><span class="n">drop_duplicates</span><span class="p">()</span>
</code></pre></div></div>

<p>The distribution of IDs in the two dataframes:</p>

<table>
  <thead>
    <tr>
      <th>¬†</th>
      <th>df1 only</th>
      <th>overlap</th>
      <th>df2 only</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td># of ids</td>
      <td>8625</td>
      <td>914</td>
      <td>8623</td>
    </tr>
  </tbody>
</table>

<p>Here is the distribution of computing times for <code class="language-plaintext highlighter-rouge">inner</code>, <code class="language-plaintext highlighter-rouge">left</code>, <code class="language-plaintext highlighter-rouge">outer</code>, <code class="language-plaintext highlighter-rouge">right</code> and <code class="language-plaintext highlighter-rouge">union-left</code>(that gives same results as <code class="language-plaintext highlighter-rouge">outer</code>) joins(I repeated each join 20 times):</p>

<p><img style="float: center;" src="/assets/img/types_of_join_computing_time.png" /></p>

<p>For these sizes of dataframes, the <code class="language-plaintext highlighter-rouge">union-left</code> join is on average ~20% faster than the equivalent <code class="language-plaintext highlighter-rouge">outer</code> join.</p>

    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2020/04/09/hn2016_falwa-release0.4.0/">
        Local wave activity calculation for Southern Hemisphere available in release0.4.0
      </a>
    </h1>

    <span class="post-date">09 Apr 2020</span>

    
        <p>[hn2016_falwa Release 0.4.0] üòÑI am happy to announce that the climate data analysis in Nakamura and Huang(2018, Science) for the southern hemisphere is also available <a href="https://github.com/csyhuang/hn2016_falwa">on GitHub</a> now! (Finally, I have time to do a thorough check of the code and make the release‚Ä¶)</p>

<p>Check out the release note for enhanced functionality:<br />
<a href="https://github.com/csyhuang/hn2016_falwa/releases/tag/0.4.0">https://github.com/csyhuang/hn2016_falwa/releases/tag/0.4.0</a></p>

<p>The documentation page has been fixed too:<br />
<a href="https://csyhuang.github.io/hn2016_falwa">https://csyhuang.github.io/hn2016_falwa</a></p>

<p>Jupyter notebook demonstrating the usage of the functions:<br />
<a href="https://github.com/csyhuang/hn2016_falwa/blob/master/examples/nh2018_science/demo_script_for_nh2018.ipynb">https://github.com/csyhuang/hn2016_falwa/blob/master/examples/nh2018_science/demo_script_for_nh2018.ipynb</a></p>

<p>If you have any questions/issues regarding the usage of the package, feel free to post on the <a href="https://github.com/csyhuang/hn2016_falwa/issues">Issue page</a> of the repo! I will help you fix them soon as I can!</p>

    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2020/02/07/tips-for-writing-more-efficient-sql/">
        Tips for writing more efficient SQL
      </a>
    </h1>

    <span class="post-date">07 Feb 2020</span>

    
        <p>Learned from colleagues some points to pay attention to when writing SQL queries. (This post will be updated from time to time.)</p>

<h1 id="partitioned-tables">Partitioned tables</h1>

<p><strong>Always</strong> specify the partition in the <code class="language-plaintext highlighter-rouge">where</code> clause. If you have to retrieve data from several partitions, loop through it one-by-one.</p>

<h1 id="distinct-elements">Distinct elements</h1>

<p>Note that the two queries</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="k">DISTINCT</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">FROM</span> <span class="n">table_X</span>
</code></pre></div></div>

<p>and</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="n">item</span> <span class="k">FROM</span> <span class="n">table_X</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="n">item</span>
</code></pre></div></div>

<p>give the same result. However, the second SQL query will be executed faster. There is no difference calling <code class="language-plaintext highlighter-rouge">distinct</code> and <code class="language-plaintext highlighter-rouge">group by</code> via (py)spark though.</p>

<h1 id="join-vs-where">JOIN v.s. WHERE</h1>

<p>Always use <code class="language-plaintext highlighter-rouge">where</code> to filter the table to be joined to the smallest, e.g.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="k">c</span><span class="p">.</span><span class="o">*</span> <span class="k">FROM</span> <span class="n">credit</span> <span class="k">c</span>
<span class="k">INNER</span> <span class="k">JOIN</span> <span class="p">(</span>
	<span class="k">SELECT</span> <span class="nb">date</span><span class="p">,</span> <span class="n">item</span> <span class="k">FROM</span> <span class="n">purchase</span>
	<span class="k">WHERE</span> <span class="nb">date</span> <span class="o">&gt;</span> <span class="mi">20190207</span>
<span class="p">)</span> <span class="n">p</span>
<span class="k">ON</span> <span class="k">c</span><span class="p">.</span><span class="nb">date</span> <span class="o">=</span> <span class="n">p</span><span class="p">.</span><span class="nb">date</span>
<span class="k">WHERE</span> <span class="k">c</span><span class="p">.</span><span class="n">eligibility</span> <span class="o">=</span> <span class="k">True</span>
</code></pre></div></div>

<p>Note that the line <code class="language-plaintext highlighter-rouge">WHERE c.eligibility = True</code> is executed to filter the table <code class="language-plaintext highlighter-rouge">credit</code> before the <code class="language-plaintext highlighter-rouge">JOIN</code>. This shrinks the table <code class="language-plaintext highlighter-rouge">credit</code> to the smallest before joining.</p>

    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2019/12/20/comic-series-on-bouldering/">
        I started a comic series about bouldering (for fun)
      </a>
    </h1>

    <span class="post-date">20 Dec 2019</span>

    
        <p>This is not about work but <strong>for fun</strong> :D</p>

<p>I recently started learning bouldering (2.5 months till now?) and that‚Äôs lots of fun! I keep updating a comic series - the <a href="https://www.instagram.com/explore/tags/matchman_bouldering_series/">Matchman Bouldering Series</a> - on <a href="https://www.instagram.com/clarescookbook/">Instagram</a>/<a href="https://matchman-bouldering-series.tumblr.com/">Tumblr</a> that records the ideas I learned from friends in every session collaborating with my college friend <a href="https://www.instagram.com/martin_ka_hei/">Martin</a>.</p>

<p>Some previews‚Ä¶</p>

<p><img src="/assets/img/thumbnails-of-matchman.png" alt="Matchman Bouldering Series" /></p>

<p>If you are fond of bouldering and have practical/physics ideas to share, ping me and see if we can collaborate! :)</p>

    
  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/page2">Older</a>
  
  
    <span class="pagination-item newer">Newer</span>
  
</div>

<div>
<p><!-- hitwebcounter Code START -->
<a href="http://www.hitwebcounter.com" target="_blank">
<img src="http://hitwebcounter.com/counter/counter.php?page=6563193&style=0006&nbdigits=5&type=page&initCount=0" title="my widget for counting" Alt="my widget for counting (since Dec24, 2016)"   border="0" >
</a> <br/>
</p>
</div>
  <link rel="stylesheet" href="/public/css/trial.css">

      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', function(e) {
          var target = e.target;

          if(!checkbox.checked ||
             sidebar.contains(target) ||
             (target === checkbox || target === toggle)) return;

          checkbox.checked = false;
        }, false);
      })(document);
    </script>
  </body>
</html>
