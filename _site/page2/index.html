<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Blog &middot; Clare S. Y. Huang
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/lanyon.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>PhD in Geophysical Sciences (UChicago). Love coding, music and writing.</p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="/">Home</a>
    <a class="sidebar-nav-item" href="/about_me.html" >About me</a>    

    

    
    
      
        
      
    
      
        
      
    
      
        
      
    
      
    
      
        
          <a class="sidebar-nav-item" href="/bookshelf/">Bookshelf</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/climate_tools/">Climate Tools</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/ds_notes/">Data Science Notes</a>
        
      
    
      
    
      
        
          <a class="sidebar-nav-item" href="/musicarrangement/">Music Arrangements</a>
        
      
    
      
        
      
    
      
        
      
    
      
        
          <a class="sidebar-nav-item" href="/publications/">Publications</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/pyspark_solutions/">PySpark/SQL Solutions</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/research/">Academic Research</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/tools/">Handy Tools</a>
        
      
    

<!--    <a class="sidebar-nav-item" href="/archive/v1.0.0.zip">Download</a> -->

    <a class="sidebar-nav-item" href="http://github.com/csyhuang/"  target="_blank">Github</a>
<!--    <span class="sidebar-nav-item">Currently v1.0.0</span> --->
  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2021 Shao Ying (Clare) Huang. All rights reserved.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/" title="Home">Clare S. Y. Huang</a>
            <small>Data Scientist | Atmospheric Dynamicist</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<div class="row">
  <div class="col-sm-8">
<!-- 
  <p class="influidcontainer">I have just completed my Ph.D degree in Geophysical Sciences in the University of Chicago and currently work as a postdoctoral research assistant in Professor Noboru Nakamura's group.
  My <a href="/research">dissertation</a> focuses on developing an atmospheric Rossby wave diagnostic theory that quantifies the severity of extreme weather events. I am now working on the search of predictive features of atmospheric blocking using the local wave activity theory I developed and some machine learning techniques.
  Check out my <a href="https://github.com/csyhuang/hn2016_falwa" target="blank">python library</a> to implement this diagnosis on climate data!
  </p>
  <p class="influidcontainer">
  I also participated in the <a href="http://insightdatascience.com">Insight Data Science Fellowship Program</a> in 2017 summer as a Health Data Fellow to learn about data science and health industry.
  Currently, I work in the Research Analytics team at <a href="http://tempus.com/">Tempus</a>.
  </p>
 -->
  <p class="influidcontainer">
  I love to share what I've learnt with others. Check out my blog posts and notes about my 
  academic research, as well as technical solutions on software engineering and data 
  science challenges.
  </p>  
  </div>
  

  <div class="col-sm-4">
<!-- 

    <img src="/assets/img/profile_pic_square.jpg">
    
 -->
    <div align="right">
      <p><a href="http://csyhuang.github.io/feed.xml"  target="_blank"><i class="fa fa-rss" aria-hidden="true"></i> RSS Feed </a></p>
      <p><a href="mailto:csyhuang@uchicago.edu"><i class="fa fa-envelope" aria-hidden="true"></i> Email </a></p>
    </div>
    
    
  </div>
</div>


<!-- 
Welcome to my personal homepage! Please use the <b>left-side menu</b> to navigate to pages related to my academic work. This index page is maintained in a blog-like manner that I'll constantly put in things I've learnt, and updated content of this website.
  </div>
</div>
 -->
<div class="clear"></div>
<hr>

<div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2019/09/25/pyspark-generate-sequences/">
        Generate sequence from an array column of pyspark dataframe
      </a>
    </h1>

    <span class="post-date">25 Sep 2019</span>

    
        <p>Suppose I have a Hive table that has a column of sequences,</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+------------------+
|          sequence|
+------------------+
|      [3, 23, 564]|
+------------------+
</code></pre></div></div>

<p>how to generate a column that contains permutations of each sequence in multiple rows? The desired output shall look like:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+------------------+------------------+
|          sequence|       permutation|
+------------------+------------------+
|      [3, 23, 564]|      [3, 23, 564]|
|      [3, 23, 564]|      [3, 564, 23]|
|      [3, 23, 564]|      [23, 3, 564]|
|      [3, 23, 564]|      [23, 564, 3]|
|      [3, 23, 564]|      [564, 3, 23]|
|      [3, 23, 564]|      [564, 23, 3]|
+------------------+------------------+
</code></pre></div></div>

<p>In order to get multiple rows out of each row, we need to use the function <code class="language-plaintext highlighter-rouge">explode</code>. First, we write a user-defined function (UDF) to return the list of permutations given a array (sequence):</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span><span class="p">,</span> <span class="n">Row</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">IntegerType</span><span class="p">,</span> <span class="n">ArrayType</span>

<span class="o">@</span><span class="n">udf_type</span><span class="p">(</span><span class="n">ArrayType</span><span class="p">(</span><span class="n">ArrayType</span><span class="p">(</span><span class="n">IntegerType</span><span class="p">())))</span>
<span class="k">def</span> <span class="nf">permutation</span><span class="p">(</span><span class="n">a_list</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="p">.</span><span class="n">permutations</span><span class="p">(</span><span class="n">a_list</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">a_list</span><span class="p">)))</span>
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">udf_type</code> function is adapted from the <a href="https://johnpaton.net/posts/clean-spark-udfs/">blog post by John Paton</a>. The output type is specified to be an array of “array of integers”.</p>

<p>The application of this function with <code class="language-plaintext highlighter-rouge">explode</code> will yield the result above:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">spark_session</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span><span class="n">Row</span><span class="p">(</span><span class="n">sequence</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">23</span><span class="p">,</span> <span class="mi">564</span><span class="p">])])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s">'permutation'</span><span class="p">,</span> <span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">permutation</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">col</span><span class="p">(</span><span class="s">'sequence'</span><span class="p">))))</span>
</code></pre></div></div>


    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2019/09/24/pyspark-could-not-serialize-object/">
        Pyspark error "Could not serialize object"
      </a>
    </h1>

    <span class="post-date">24 Sep 2019</span>

    
        <div>
            <p>This post is related to the idea discuss in the post <a href="https://www.placeiq.com/2017/11/how-to-solve-non-serializable-errors-when-instantiating-objects-in-spark-udfs/">“How to Solve Non-Serializable Errors When Instantiating Objects In Spark UDFs”</a>. Here I discuss the solution in a hypothetical scenario in pyspark.

        </div>
        <input type="checkbox" class="read-more-state" id="/2019/09/24/pyspark-could-not-serialize-object/"/>
        <div class="read-more">
            
Suppose I have a class to transform string to sum of numbers like this:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pyspark.sql.functions</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">udf</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">IntegerType</span>

<span class="k">class</span> <span class="nc">AnimalsToNumbers</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spark</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_mapping</span> <span class="o">=</span> <span class="p">{</span><span class="s">'elephant'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s">'bear'</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s">'cat'</span><span class="p">:</span> <span class="mi">9</span><span class="p">}</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_spark</span> <span class="o">=</span> <span class="n">spark</span>
        
    <span class="k">def</span> <span class="nf">addition</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">animal_str</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">([</span><span class="bp">self</span><span class="p">.</span><span class="n">_mapping</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">animal_str</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">'+'</span><span class="p">)])</span>
    
    <span class="k">def</span> <span class="nf">add_up_animals</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">):</span>
        <span class="n">addition_udf</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">udf</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">addition</span><span class="p">,</span> <span class="n">IntegerType</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">df</span><span class="p">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s">'sum'</span><span class="p">,</span> <span class="n">addition_udf</span><span class="p">(</span><span class="s">'animal'</span><span class="p">))</span>
</code></pre></div></div>

<p>(In practical cases, <code class="language-plaintext highlighter-rouge">self._mapping</code> is a huge object containing the dictionary and other attributes that are derived from methods in the <code class="language-plaintext highlighter-rouge">AnimalsToNumbers</code> class.) If I want to transform a dataframe <code class="language-plaintext highlighter-rouge">df</code> that looks like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-------------+
|       animal|
+-------------+
|elephant+bear|
|     cat+bear|
+-------------+
</code></pre></div></div>

<p>The operation</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">AnimalsToNumbers</span><span class="p">(</span><span class="n">spark</span><span class="p">).</span><span class="n">add_up_animals</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div></div>

<p>will lead to an error like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---------------------------------------------------------------------------
Py4JError                                 Traceback (most recent call last)
~/anaconda3/envs/pyspark_demo/lib/python3.5/site-packages/pyspark/serializers.py in dumps(self, obj)
    589         try:
--&gt; 590             return cloudpickle.dumps(obj, 2)
    591         except pickle.PickleError:
...
PicklingError: Could not serialize object: Py4JError: An error occurred while calling o25.__getstate__. Trace:
py4j.Py4JException: Method __getstate__([]) does not exist
	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)
	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)
	at py4j.Gateway.invoke(Gateway.java:274)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)
</code></pre></div></div>

<p>The issue is that, as <code class="language-plaintext highlighter-rouge">self._mapping</code> appears in the function <code class="language-plaintext highlighter-rouge">addition</code>, when applying <code class="language-plaintext highlighter-rouge">addition_udf</code> to the pyspark dataframe, the object <code class="language-plaintext highlighter-rouge">self</code> (i.e. the <code class="language-plaintext highlighter-rouge">AnimalsToNumbers</code> class) has to be serialized but it can’t be.</p>

<p>A (surprisingly simple) way is to create a reference to the dictionary (<code class="language-plaintext highlighter-rouge">self._mapping</code>) but not the object:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">AnimalsToNumbers</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spark</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_mapping</span> <span class="o">=</span> <span class="p">{</span><span class="s">'elephant'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s">'bear'</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s">'cat'</span><span class="p">:</span> <span class="mi">9</span><span class="p">}</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_spark</span> <span class="o">=</span> <span class="n">spark</span>
        
    
    <span class="k">def</span> <span class="nf">add_up_animals</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">):</span>
        <span class="n">mapping</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_mapping</span>
        <span class="k">def</span> <span class="nf">addition</span><span class="p">(</span><span class="n">animal_str</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">sum</span><span class="p">([</span><span class="n">mapping</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">animal_str</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">'+'</span><span class="p">)])</span>

        <span class="n">addition_udf</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">udf</span><span class="p">(</span><span class="n">addition</span><span class="p">,</span> <span class="n">IntegerType</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">df</span><span class="p">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s">'sum'</span><span class="p">,</span> <span class="n">addition_udf</span><span class="p">(</span><span class="s">'animal'</span><span class="p">))</span>

</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">AnimalsToNumbers(spark).add_up_animals(df).show()</code> would yield:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-------------+---+
|       animal|sum|
+-------------+---+
|elephant+bear|  5|
|     cat+bear| 13|
+-------------+---+

</code></pre></div></div>

<p>Yay :)</p>


        </div>
        <label for="/2019/09/24/pyspark-could-not-serialize-object/" class="read-more-trigger"></label>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2019/09/16/json-in-postgresql/">
        Handling JSON in PostgreSQL
      </a>
    </h1>

    <span class="post-date">16 Sep 2019</span>

    
        <p>Found a useful <a href="https://devhints.io/postgresql-json">cheatsheet</a> that listed out operations on JSON in PostgreSQL.</p>

<p>If I want to list the rows where column <code class="language-plaintext highlighter-rouge">col1</code> in table <code class="language-plaintext highlighter-rouge">table1</code> contains a JSON object with the key <code class="language-plaintext highlighter-rouge">key1</code>, I can use:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">table1</span>
<span class="k">where</span> <span class="n">col1</span><span class="o">-&gt;</span><span class="s1">'key1'</span> <span class="k">IS</span> <span class="k">NOT</span> <span class="k">NULL</span>
</code></pre></div></div>

    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2019/09/15/lwa-package-updated-to-new-version/">
        Local wave activity package updated to version 0.3.7
      </a>
    </h1>

    <span class="post-date">15 Sep 2019</span>

    
        <p>The <a href="https://github.com/csyhuang/hn2016_falwa">python package</a> <code class="language-plaintext highlighter-rouge">hn2016_falwa</code> has just been updated with the following changes:</p>
<ul>
  <li>Switched the unittest framework from <code class="language-plaintext highlighter-rouge">unittest</code> to <code class="language-plaintext highlighter-rouge">pytest</code></li>
  <li>Improved interface of the QGField object</li>
  <li>Added a new function <code class="language-plaintext highlighter-rouge">hn2016_falwa.download_data.retrieve_erai</code> to download ERA-Interim data (but not connected to the main program yet)</li>
</ul>

<p>My package uses <code class="language-plaintext highlighter-rouge">f2py</code>. When switching from <code class="language-plaintext highlighter-rouge">unittest</code> to <code class="language-plaintext highlighter-rouge">pytest</code>, there are several changes to make in <code class="language-plaintext highlighter-rouge">setup.py</code> and <code class="language-plaintext highlighter-rouge">.travis</code> to accommodate such usage:</p>

<p>In <code class="language-plaintext highlighter-rouge">setup</code> (<code class="language-plaintext highlighter-rouge">numpy.distutils.core.setup</code>), remove the argument</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_suite</span><span class="o">=</span><span class="s">'tests.my_module_suite'</span>
</code></pre></div></div>
<p>and add:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">packages</span><span class="o">=</span><span class="n">find_packages</span><span class="p">(),</span>
    <span class="n">setup_requires</span><span class="o">=</span><span class="p">[</span><span class="s">'pytest-runner'</span><span class="p">],</span>
    <span class="n">tests_require</span><span class="o">=</span><span class="p">[</span><span class="s">'pytest'</span><span class="p">],</span>
</code></pre></div></div>

<p>In <code class="language-plaintext highlighter-rouge">.travis</code>, the <code class="language-plaintext highlighter-rouge">script</code> section looks like:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>script:
  - python setup.py pytest
</code></pre></div></div>

    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2019/09/10/colloquium-at-uw-madison/">
        Visit to AOS at UW-Madison
      </a>
    </h1>

    <span class="post-date">10 Sep 2019</span>

    
        <p>I visited the <a href="https://www.aos.wisc.edu/">Department of Atmospheric and Oceanic Sciences</a> at the <a href="https://www.wisc.edu/">University of Wisconsin-Madison</a> for two days and had a lot of fun discussing atmospheric (and machine learning) research with the scientists there. Thanks Prof. Jon Martin for inviting me over!</p>

<p>The colloquium I gave on Monday was an overview of the finite-amplitude local Rossby wave activity theory and its application to study blocking. We learned from this framework that atmospheric blocking can be modelled as a traffic jam problem. I also mentioned the follow-up work by <a href="https://journals.ametsoc.org/toc/atsc/current">Paradise et al. (2019, JAS)</a> that discusses the implication of this notion.</p>

<p>The slides for my colloquium can be found below:</p>

<p><a href="https://www.dropbox.com/s/ladgdo6tjkyhvmo/clare-uw-colloquium-20190909.pdf?dl=1"><img src="/assets/img/uw-colloquium-thumbnail.png" alt="Slides for UW-Madison Colloquium" /></a></p>

    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2019/07/24/rnn-papers/">
        Papers on architecture of Recurrent Neural Networks (RNN)
      </a>
    </h1>

    <span class="post-date">24 Jul 2019</span>

    
        <p>Bookmarking some papers mentioned in Andrew Ng’s course <a href="https://www.coursera.org/learn/nlp-sequence-models">Sequence Models</a>:</p>

<h3 id="gate-recurrent-unit-gru">Gate Recurrent Unit (GRU)</h3>

<ul>
  <li>
    <p>Cho, K., Van Merriënboer, B., Bahdanau, D., &amp; Bengio, Y. (2014). <a href="https://arxiv.org/abs/1409.1259">On the properties of neural machine translation: Encoder-decoder approaches</a>. <em>arXiv preprint arXiv:1409.1259</em>.</p>
  </li>
  <li>
    <p>Chung, J., Gulcehre, C., Cho, K., &amp; Bengio, Y. (2014). <a href="https://arxiv.org/abs/1412.3555">Empirical evaluation of gated recurrent neural networks on sequence modeling</a>. <em>arXiv preprint arXiv:1412.3555</em>.</p>
  </li>
</ul>

<h3 id="long-short-term-memory-lstm">Long short-term memory (LSTM)</h3>

<ul>
  <li>Hochreiter, S., &amp; Schmidhuber, J. (1997). <a href="https://www.bioinf.jku.at/publications/older/2604.pdf">Long short-term memory</a>. <em>Neural computation</em>, 9(8), 1735-1780.</li>
</ul>

<p>(More to update)</p>

    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2019/06/20/useful-git-commands/">
        Useful Git commands at work
      </a>
    </h1>

    <span class="post-date">20 Jun 2019</span>

    
        <div>
            <p>Below are solutions I curated online to solve problems related to Git when collaborating with others and working on several branches together. <em>This post will be updated from time to time.</em>

        </div>
        <input type="checkbox" class="read-more-state" id="/2019/06/20/useful-git-commands/"/>
        <div class="read-more">
            </p>
<h3 id="copy-a-file-from-one-branch-to-another">Copy a file from one branch to another</h3>
<p>To copy a file to the current branch from another branch (<a href="https://stackoverflow.com/questions/307579/how-do-i-copy-a-version-of-a-single-file-from-one-git-branch-to-another/7099164">ref</a>)</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git checkout another_branch the_file_you_want.txt
</code></pre></div></div>

<h3 id="merge-changes-from-master-branch-to-yours">Merge changes from master branch to yours</h3>
<p>To merge changes from another branch to yours, you can use <code class="language-plaintext highlighter-rouge">merge</code> or <code class="language-plaintext highlighter-rouge">rebase</code> depending on the preferred commit order. BitBucket has a <a href="https://www.atlassian.com/git/tutorials/merging-vs-rebasing">nice tutorial</a> discussing the difference btween the two. Usually I’d love to have the changes pulled from another branch as a single commit with <code class="language-plaintext highlighter-rouge">git merge</code>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git checkout master      # the branch with changes
git pull                 # pull the remote changes to local master branch
git checkout mybranch    # go back to mybranch
git merge master         # incorporate the changes into mybranch
</code></pre></div></div>

<h3 id="how-to-use-git-revert">How to use <code class="language-plaintext highlighter-rouge">git revert</code></h3>
<p><a href="https://www.atlassian.com/git/tutorials/undoing-changes/git-revert">Useful tutorial</a> from BitBucket on <code class="language-plaintext highlighter-rouge">git revert</code>.</p>

<h3 id="compare-differences-between-branches-and-output-the-results">Compare differences between branches and output the results</h3>
<p>If you want to compare the difference between your (more updated) branch and the master branch, use the command</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git diff master..your_branch
</code></pre></div></div>
<p>You can save the comparison results into a text file with colors by</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git diff master..your_branch &gt; your_branch_to_master.diff
</code></pre></div></div>
<p>The color can be viewed when you open the <code class="language-plaintext highlighter-rouge">.diff</code> file with <a href="https://www.sublimetext.com/">Sublime</a>.</p>

<h3 id="update-password-for-git-on-mac-os-x">Update password for Git on Mac OS X</h3>
<p>use the following command</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git config --global credential.helper osxkeychain
</code></pre></div></div>

<p>[to be continued]</p>


        </div>
        <label for="/2019/06/20/useful-git-commands/" class="read-more-trigger"></label>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2019/06/13/comparison-between-different-statistical-language-models/">
        Comparison between different statistical language models
      </a>
    </h1>

    <span class="post-date">13 Jun 2019</span>

    
        <p>When researching on different machine learning models for modeling languages (i.e. sequence model), here are some useful resources I found online:</p>

<h3 id="articles">Articles</h3>

<ul>
  <li><a href="https://www.alibabacloud.com/blog/hmm-memm-and-crf-a-comparative-analysis-of-statistical-modeling-methods_592049?spm=a2c41.11544604.0.0">HMM, MEMM, and CRF: A Comparative Analysis of Statistical Modeling Methods</a> by Alibaba Clouder</li>
  <li><a href="http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/">Introduction to Conditional Random Fields</a> by Edwin Chen</li>
  <li><a href="http://homepages.inf.ed.ac.uk/csutton/publications/crftut-fnt.pdf">An Introduction to Conditional Random Fields</a> by Charles Sutton and Andrew McCallum</li>
  <li><a href="http://www.albertauyeung.com/post/python-sequence-labelling-with-crf/">Performing Sequence Labelling using CRF in Python</a> by Albert AuYeung</li>
  <li>(more to update)</li>
</ul>

<h3 id="courses">Courses</h3>
<ul>
  <li><a href="http://www.yisongyue.com/courses/cs155/2016_winter/">Machine Learning &amp; Data Mining</a> by <a href="mailto:yyue@caltech.edu">Yisong Yue</a> at CalTech</li>
</ul>

<!-- https://towardsdatascience.com/conditional-random-field-tutorial-in-pytorch-ca0d04499463

http://web.cse.ohio-state.edu/~fosler-lussier.1/papers/IEEE_CRF_SALP_FoslerEtalPreprint.pdf

https://web.stanford.edu/~jurafsky/asru09.pdf

https://towardsdatascience.com/review-crf-rnn-conditional-random-fields-as-recurrent-neural-networks-semantic-segmentation-a11eb6e40c8c

http://www.robots.ox.ac.uk/~szheng/papers/CRFasRNN.pdf


https://blog.paperspace.com/recurrent-neural-networks-part-1-2/

https://medium.com/deep-writing

https://www.quora.com/Are-recurrent-neural-networks-RNNs-considered-a-generative-model-in-Machine-Learning


https://towardsdatascience.com/evaluating-text-output-in-nlp-bleu-at-your-own-risk-e8609665a213

 -->

    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2018/12/14/read-libsvm-to-pyspark-df/">
        Read libsvm files into PySpark dataframe
      </a>
    </h1>

    <span class="post-date">14 Dec 2018</span>

    
        <div>
            <p>I wanted to load the libsvm files provided in <a href="https://github.com/tensorflow/ranking">tensorflow/ranking</a> into PySpark dataframe, but couldn’t find existing modules for that. Here is a version I wrote to do the job. (Disclaimer: not the most elegant solution, but it works.)

        </div>
        <input type="checkbox" class="read-more-state" id="/2018/12/14/read-libsvm-to-pyspark-df/"/>
        <div class="read-more">
            
First of all, load the pyspark utilities required.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">pyspark</span> <span class="kn">import</span> <span class="n">SparkContext</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span><span class="p">,</span> <span class="n">Row</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">SparseVector</span>
</code></pre></div></div>

<p>Initiate a spark session for creation of dataframe.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="p">(</span><span class="s">"local"</span><span class="p">,</span> <span class="s">"read_libsvm"</span><span class="p">)</span>
<span class="n">spark_session</span> <span class="o">=</span> <span class="n">SparkSession</span> \
    <span class="p">.</span><span class="n">builder</span> \
    <span class="p">.</span><span class="n">appName</span><span class="p">(</span><span class="s">"read_libsvm"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">getOrCreate</span><span class="p">()</span>
</code></pre></div></div>

<p>Get the path to the data files.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">_TRAIN_DATA_PATH</span><span class="o">=</span><span class="s">"data/train.txt"</span>
<span class="n">_TEST_DATA_PATH</span><span class="o">=</span><span class="s">"data/test.txt"</span>
</code></pre></div></div>

<p>Here is the module I wrote for the purpose:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">read_libsvm</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">query_id</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="s">'''
    A utility function that takes in a libsvm file and turn it to a pyspark dataframe.

    Args:
        filepath (str): The file path to the data file.
        query_id (bool): whether 'qid' is present in the file.

    Returns:
        A pyspark dataframe that contains the data loaded.
    '''</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="s">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">raw_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">.</span><span class="n">split</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">f</span><span class="p">.</span><span class="n">readlines</span><span class="p">()]</span>

    <span class="n">train_outcome</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">raw_data</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">query_id</span><span class="p">:</span>
        <span class="n">train_qid</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">lstrip</span><span class="p">(</span><span class="s">'qid:'</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">raw_data</span><span class="p">]</span>

    <span class="n">index_value_dict</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">raw_data</span><span class="p">:</span>
        <span class="n">index_value_dict</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="nb">dict</span><span class="p">([(</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">':'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">':'</span><span class="p">)[</span><span class="mi">1</span><span class="p">]))</span>
                                       <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">row</span><span class="p">[(</span><span class="mi">1</span> <span class="o">+</span> <span class="nb">int</span><span class="p">(</span><span class="n">query_id</span><span class="p">)):]]))</span>

    <span class="n">max_idx</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">max</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">keys</span><span class="p">())</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">index_value_dict</span><span class="p">])</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">Row</span><span class="p">(</span>
            <span class="n">qid</span><span class="o">=</span><span class="n">train_qid</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
            <span class="n">label</span><span class="o">=</span><span class="n">train_outcome</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
            <span class="n">feat_vector</span><span class="o">=</span><span class="n">SparseVector</span><span class="p">(</span><span class="n">max_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">index_value_dict</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">index_value_dict</span><span class="p">))</span>
    <span class="p">]</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">spark_session</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">rows</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">df</span>

</code></pre></div></div>

<p>Let’s see how the train and test sets look like in the tf-ranking package:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_df</span> <span class="o">=</span> <span class="n">read_libsvm</span><span class="p">(</span><span class="n">_TRAIN_DATA_PATH</span><span class="p">)</span>
<span class="n">test_df</span> <span class="o">=</span> <span class="n">read_libsvm</span><span class="p">(</span><span class="n">_TEST_DATA_PATH</span><span class="p">)</span>

<span class="n">train_df</span><span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+--------------------+-----+---+
|         feat_vector|label|qid|
+--------------------+-----+---+
|(137,[5,13,17,42,...|    0|  1|
|(137,[11,13,18,30...|    2|  1|
|(137,[11,27,29,39...|    2|  1|
|(137,[5,10,26,31,...|    1|  1|
|(137,[13,17,22,24...|    2|  2|
+--------------------+-----+---+
only showing top 5 rows
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_df</span><span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+--------------------+-----+---+
|         feat_vector|label|qid|
+--------------------+-----+---+
|(137,[2,7,37,40,4...|    1|  1|
|(137,[1,8,12,15,2...|    2|  1|
|(137,[4,11,15,16,...|    0|  1|
|(137,[14,19,20,33...|    0|  1|
|(137,[9,12,19,26,...|    1|  2|
+--------------------+-----+---+
only showing top 5 rows
</code></pre></div></div>


        </div>
        <label for="/2018/12/14/read-libsvm-to-pyspark-df/" class="read-more-trigger"></label>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2018/11/28/pyspark-solution-1/">
        Simple pyspark solutions
      </a>
    </h1>

    <span class="post-date">28 Nov 2018</span>

    
        <p>Here is a curation of some solutions to simple problems encountered when working with pyspark.</p>

<h3 id="how-to-replace-string-in-a-column">How to replace string in a column?</h3>

<p><a href="https://stackoverflow.com/questions/37038014/pyspark-replace-strings-in-spark-dataframe-column">Source</a></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">new_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">withColumn</span><span class="p">(</span><span class="n">col_name</span><span class="p">,</span> <span class="n">regexp_replace</span><span class="p">(</span><span class="n">col_name</span><span class="p">,</span> <span class="n">pattern</span><span class="p">,</span> <span class="n">replacement</span><span class="p">))</span>
</code></pre></div></div>

<h3 id="how-to-avoid-duplicate-columns-when-joining-two-dataframe-on-columns-with-the-same-name">How to avoid duplicate columns when joining two dataframe on columns with the same name?</h3>

<p><a href="https://docs.databricks.com/spark/latest/faq/join-two-dataframes-duplicated-column.html">Source</a></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">left_df</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">right_df</span><span class="p">,</span> <span class="p">[</span><span class="s">"name"</span><span class="p">])</span>
</code></pre></div></div>

    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2018/11/19/ubuntu-on-windows/">
        Ubuntu on Windows
      </a>
    </h1>

    <span class="post-date">19 Nov 2018</span>

    
        <p>Found a useful article: <a href="https://www.howtogeek.com/261383/how-to-access-your-ubuntu-bash-files-in-windows-and-your-windows-system-drive-in-bash/">How to Access Your Ubuntu Bash Files in Windows (and Your Windows System Drive in Bash)</a>.</p>

    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2018/07/01/python-packaging/">
        Resources on Python Packaging
      </a>
    </h1>

    <span class="post-date">01 Jul 2018</span>

    
        <p>On my way figuring out how to properly write unit test for my python package, 
I have come across the useful pages below:</p>

<ul>
  <li><a href="http://python-packaging.readthedocs.io/">Python Packaging (official page)</a> 
(comprehensive manual)</li>
  <li><a href="https://docs.pytest.org/en/latest/goodpractices.html">SetupTools (official page)</a>: I 
read about how to use the development mode here.</li>
  <li><a href="http://docs.python-guide.org/en/latest/writing/tests/">Testing Your Code</a> 
from the Hitchhiker’s Guide to Python (introductory)</li>
  <li><a href="https://docs.pytest.org/en/latest/goodpractices.html">Good Integration Practices</a> 
from pytest</li>
  <li>(more to update)</li>
</ul>

<p>Unit tests are worth the time writing to make sure your package works as you expected. 
I also found some commercial packages using unit tests as sample script for user to 
refer to (e.g. <a href="https://github.com/allenai/allennlp">AllenNLP</a>).</p>


    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2018/06/24/set-up-dash-app-on-pythonanywhere/">
        Setting up a Dash App on PythonAnywhere
      </a>
    </h1>

    <span class="post-date">24 Jun 2018</span>

    
        <p>After opening an account on <a href="http://pythonanywhere.com">pythonanywhere</a>, 
go to the <strong>Web</strong> tab and select <strong>Add a new web app</strong>.</p>

<p>When prompted to select a Python Web framework, choose <strong>Flask</strong>.</p>

<p>Choose your python version. Here, I am choosing <strong>Python 3.6 (Flask 0.12)</strong>.</p>

<p>Enter a path for a Python file I wish to hold my Dash app. I entered:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/home/username/mysite/dashing_demo_app.py
</code></pre></div></div>

<p>Put the script of your Dash app in <code class="language-plaintext highlighter-rouge">dashing_demo_app.py</code>. You can use the script in the sample file 
<a href="https://github.com/conradho/dashingdemo/blob/master/dashing_demo_app.py">dashing_demo_app.py</a> 
provided on the GitHub repo of pythonanywhere’s staff.</p>

<p>Next I have to set up a virtual environment that the app is running in. I am using the 
<a href="https://github.com/conradho/dashingdemo/blob/master/requirements3.6.txt">requirements3.6.txt</a> 
provided in the above GitHub repo.</p>

<p>Go to the <strong>Files</strong> tab to create <code class="language-plaintext highlighter-rouge">requirements3.6.txt</code> in your home directory. Then, 
go to the <strong>Consoles</strong> tab to start a new <em>bash</em> session. 
Create a virtual environment <em>dashappenv</em> with the following command in the home directory:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mkvirtualenv dashappenv --python=/usr/bin/python3.6
pip install -r requirements3.6.txt
</code></pre></div></div>

<p>Then, go to the <strong>Web</strong> tab and enter under <strong>Virtualenv</strong> the path of your virtual environment:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/home/username/.virtualenvs/dashappenv
</code></pre></div></div>

<p>Lastly, modify your WSGI file. Instead of</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from dashing_demo_app import app as application
</code></pre></div></div>
<p>provided, enter</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from dashing_demo_app import app
application = app.server
</code></pre></div></div>
<p>to import your app.</p>

<p>It’s all done. Go to <strong>Web</strong> to reload your app. You can then click the URL of your webapp and see it running. :) 
Here is the <a href="http://csyhuang.pythonanywhere.com">sample webapp</a> I built based on the example in 
<a href="https://dash.plot.ly/getting-started">Dash tutorial</a>.</p>


    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2018/05/24/our-paper-on-science/">
        Published on Science!
      </a>
    </h1>

    <span class="post-date">24 May 2018</span>

    
        <p>Our paper, <a href="https://doi.org/10.1126/science.aat0721">Nakmaura and Huang (2018), Atmospheric blocking as a traffic jam in the jet stream</a> 
is now available on Science!</p>

<p><a href="https://doi.org/10.1126/science.aat0721" target="_blank"><img src="/assets/img/NH18-Screenshot.png" alt="NH18 Science Paper Preview" style="width: 100%;" /></a></p>

<p>Here is the 
<a href="https://news.uchicago.edu/story/new-theory-finds-traffic-jams-jet-stream-cause-abnormal-weather-patterns">press release</a> 
from UChicago about the publication.</p>

<p>For interested researchers, the sample script to reproduce the results can be found in the directory 
<a href="https://github.com/csyhuang/hn2016_falwa/tree/master/examples/nh2018_science">nh2018_science</a> 
of the my python package’s GitHub repo <a href="https://github.com/csyhuang/hn2016_falwa">hn2016_falwa</a>. 
You can download ERA-Interim reanalysis data with <code class="language-plaintext highlighter-rouge">download_example.py</code> to run the local wave 
activity and flux analysis in the jupyter notebook demo <a href="https://github.com/csyhuang/hn2016_falwa/blob/master/examples/nh2018_science/demo_script_for_nh2018.ipynb">demo_script_for_nh2018.ipynb</a>.</p>

<p>Have fun and feel free to email me (csyhuang at uchicago.edu) if you are interested 
in using the code and/or have questions about it.</p>

    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2018/04/12/installing-stanfordCoreNLP/">
        Installing Stanford Core NLP package on Mac OS X
      </a>
    </h1>

    <span class="post-date">12 Apr 2018</span>

    
        <div>
            <p>I am following instructions on the <a href="https://github.com/stanfordnlp/CoreNLP">GitHub page of Stanford Core NLP</a> 
under <strong>Build with Ant</strong>. To install <code class="language-plaintext highlighter-rouge">ant</code>, you can use homebrew:

        </div>
        <input type="checkbox" class="read-more-state" id="/2018/04/12/installing-stanfordCoreNLP/"/>
        <div class="read-more">
            </p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ brew install ant
</code></pre></div></div>

<p>In Step 5, you have to include the .jar files in the directory <code class="language-plaintext highlighter-rouge">CoreNLP/lib</code> and 
<code class="language-plaintext highlighter-rouge">CoreNLP/liblocal</code> in your <code class="language-plaintext highlighter-rouge">CLASSPATH</code>. To do this, first, I install <em>coreutils</em>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew install coreutils
</code></pre></div></div>

<p>such that I can use the utility <code class="language-plaintext highlighter-rouge">realpath</code> there. Then, I include the following in my <code class="language-plaintext highlighter-rouge">~/.bashrc</code>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for file in `find /Users/clare.huang/CoreNLP/lib/ -name "*.jar"`;
  do export CLASSPATH="$CLASSPATH:`realpath $file`";
done

for file in `find /Users/clare.huang/CoreNLP/liblocal/ -name "*.jar"`;
  do export CLASSPATH="$CLASSPATH:`realpath $file`";
done
</code></pre></div></div>

<p>(I guess there are better ways to combine the commands above. Let me know if there are.)</p>

<p>To run CoreNLP, I have to download the latest version of it, and place it in the directory 
<code class="language-plaintext highlighter-rouge">CoreNLP/</code>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wget http://nlp.stanford.edu/software/stanford-corenlp-full-2018-01-31.zip
</code></pre></div></div>

<p>The latest version is available on 
their <a href="https://stanfordnlp.github.io/CoreNLP/download.html#steps">official website</a>. Unzip 
it, and add all the .jar there to the $CLASSPATH.</p>

<p>Afterwards, you shall be able to run CoreNLP with the commands provided 
in <a href="https://www.khalidalnajjar.com/setup-use-stanford-corenlp-server-python/">the blogpost of Khalid Alnajjar</a> 
(under <strong>Running Stanford CoreNLP Server</strong>). If you have no problem starting the server, 
you shall be able to see the interface on your browser at http://localhost:9000/:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>java -mx4g -cp "*" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -annotators "tokenize,ssplit,pos,lemma,parse,sentiment" -port 9000 -timeout 30000
</code></pre></div></div>

<p>Yay. Next, I will try setting up the python interface.</p>

        </div>
        <label for="/2018/04/12/installing-stanfordCoreNLP/" class="read-more-trigger"></label>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2018/04/11/installing-java-on-mac/">
        Installing java on Mac
      </a>
    </h1>

    <span class="post-date">11 Apr 2018</span>

    
        <div>
            <p>The information of this post was learnt from <a href="https://stackoverflow.com/questions/38921362/javas-path-still-usr-bin-java-after-brew-cask-install-java">this StackOverflow post</a> and 
also <a href="http://davidcai.github.io/blog/posts/install-multiple-jdk-on-mac/">David Cai’s blog post</a> on 
how to install multiple Java version on Mac OS High Sierra.

        </div>
        <input type="checkbox" class="read-more-state" id="/2018/04/11/installing-java-on-mac/"/>
        <div class="read-more">
            </p>

<p>With <code class="language-plaintext highlighter-rouge">brew cask</code> installed on Mac (see <a href="https://github.com/caskroom/homebrew-cask/blob/master/USAGE.md">homebrew-cask instructions</a>), 
different versions of java can be installed via the command (I want to install java9 here, for example):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew tap caskroom/versions
brew cask install java9
</code></pre></div></div>

<p>After installing, the symlink <code class="language-plaintext highlighter-rouge">/usr/bin/java</code> is still pointing to the old native Java. You can check 
where it points to with the command <code class="language-plaintext highlighter-rouge">ls -la /usr/bin/java</code>. It is probably pointing to the old native 
java path:
<code class="language-plaintext highlighter-rouge">
/System/Library/Frameworks/JavaVM.framework/Versions/Current/Commands/java
</code>.</p>

<p>However, homebrew installed java into the directory
<code class="language-plaintext highlighter-rouge">/Library/Java/JavaVirtualMachines/jdkx.x.x_xxx.jdk/Contents/Home</code>.</p>

<p>To easily switch between different java environments, you can use <code class="language-plaintext highlighter-rouge">jEnv</code>. The installing 
instructions can be found on <a href="http://www.jenv.be/">jEnv’s official page</a>.</p>

        </div>
        <label for="/2018/04/11/installing-java-on-mac/" class="read-more-trigger"></label>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2018/03/30/adding-rss-feed/">
        Adding an RSS feed to this site
      </a>
    </h1>

    <span class="post-date">30 Mar 2018</span>

    
        <p><a href="http://csyhuang.github.io/feed.xml">Here is the link</a> 
to the RSS feed of this blog.</p>

<p>Thanks to the instructions on 
<a href="http://joelglovier.com/writing/rss-for-jekyll" target="_blank">Joel Glovier’s blog post</a>.</p>

    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2018/02/23/ECMWF-download/">
        Python Library and scripts for downloading ERA-Interim Data
      </a>
    </h1>

    <span class="post-date">23 Feb 2018</span>

    
        <div>
            <h3 id="update-ecmwf-api-clients-on-pip-and-conda">Update: ECMWF API Clients on pip and conda</h3>

<p>The ECMWF API Python Client is now available on pypi and anaconda.<br />
The Climate Corporation has distributed the ECMWF API Python Client on 
pypi. Now it can be installed via:</p>

<blockquote>
  <p>pip install ecmwf-api-client</p>
</blockquote>

<p>Anaconda users on OS X/linux system can install the package via:</p>

<blockquote>
  <p>conda install -c bioconda ecmwfapi</p>
</blockquote>

<!-- 
### Old steps (1-3)

```
(1) Installing the package requires the python Setuptools. You can set it up locally with the command:

> wget https://bootstrap.pypa.io/ez_setup.py -O - | python - --user

(2) Download the Python library package and unzip it (You can do it in any directory)
> wget https://software.ecmwf.int/wiki/download/attachments/56664858/ecmwf-api-client-python.tgz
> tar zxf ecmwf-api-client-python.tgz

You shall see four items extracted:
- example.py
- ecmwfapi/__init__.py
- ecmwfapi/api.py
- setup.py

(3) In the directory with these four items, install the package with:
> python setup.py install --user
```
 -->

        </div>
        <input type="checkbox" class="read-more-state" id="/2018/02/23/ECMWF-download/"/>
        <div class="read-more">
            
<p>To use the sample script, you need an API key ( .ecmwfapirc ) placed in your home directory. You can retrieve that by logging in: https://api.ecmwf.int/v1/key/
Create a file named “.ecmwfapirc” in your home directory and put in the content shown on the page:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{
    "url"   : "https://api.ecmwf.int/v1",
    "key"   : "(...)",
    "email" : "(...)"
}
</code></pre></div></div>

<p>After doing that, in the directory with the sample script example.py, you can test the package by running it:</p>
<blockquote>
  <p>python example.py</p>
</blockquote>

<p>You should see it successfully retrieves a .grib file if the package has been set up properly.</p>

<p>There are <a href="https://software.ecmwf.int/wiki/display/WEBAPI/Python+ERA-interim+examples">sample scripts</a> 
available on the ECMWF website (look under “Same request NetCDF format”). Below is a example of python 
script I wrote to retrieves zonal wind, meridional wind and temperature data at all pressure levels 
during the time period 2017-07-01 to 2017-07-31 in 6-hour intervals:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#!/usr/bin/env python
</span><span class="kn">from</span> <span class="nn">ecmwfapi</span> <span class="kn">import</span> <span class="n">ECMWFDataServer</span>
<span class="n">server</span> <span class="o">=</span> <span class="n">ECMWFDataServer</span><span class="p">()</span>

<span class="n">param_u</span><span class="p">,</span> <span class="n">param_v</span><span class="p">,</span> <span class="n">param_t</span> <span class="o">=</span> <span class="s">"131.128"</span><span class="p">,</span> <span class="s">"132.128"</span><span class="p">,</span> <span class="s">"130.128"</span>

<span class="k">for</span> <span class="n">param_string</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="s">"_u"</span><span class="p">,</span> <span class="s">"_v"</span><span class="p">,</span> <span class="s">"_t"</span><span class="p">],</span>
                               <span class="p">[</span><span class="n">param_u</span><span class="p">,</span> <span class="n">param_v</span><span class="p">,</span> <span class="n">param_t</span><span class="p">]):</span>

    <span class="n">server</span><span class="p">.</span><span class="n">retrieve</span><span class="p">({</span>
        <span class="s">"class"</span><span class="p">:</span> <span class="s">"ei"</span><span class="p">,</span>
        <span class="s">"dataset"</span><span class="p">:</span> <span class="s">"interim"</span><span class="p">,</span>
        <span class="s">"date"</span><span class="p">:</span> <span class="s">"2017-07-01/to/2017-07-31"</span><span class="p">,</span>
        <span class="s">"expver"</span><span class="p">:</span> <span class="s">"1"</span><span class="p">,</span>
        <span class="s">"grid"</span><span class="p">:</span> <span class="s">"1.5/1.5"</span><span class="p">,</span>
        <span class="s">"levelist"</span><span class="p">:</span> <span class="s">"1/2/3/5/7/10/20/30/50/70/100/125/150/175/200/225/250/300/350/400/450/500/550/600/650/700/750/775/800/825/850/875/900/925/950/975/1000"</span><span class="p">,</span>
        <span class="s">"levtype"</span><span class="p">:</span> <span class="s">"pl"</span><span class="p">,</span>
        <span class="s">"param"</span><span class="p">:</span> <span class="n">param</span><span class="p">,</span>
        <span class="s">"step"</span><span class="p">:</span> <span class="s">"0"</span><span class="p">,</span>
        <span class="s">"stream"</span><span class="p">:</span> <span class="s">"oper"</span><span class="p">,</span>
        <span class="s">"format"</span><span class="p">:</span> <span class="s">"netcdf"</span><span class="p">,</span>
        <span class="s">"time"</span><span class="p">:</span> <span class="s">"00:00:00/06:00:00/12:00:00/18:00:00"</span><span class="p">,</span>
        <span class="s">"type"</span><span class="p">:</span> <span class="s">"an"</span><span class="p">,</span>
        <span class="s">"target"</span><span class="p">:</span> <span class="s">"2017-07-01/to/2017-07-31"</span> <span class="o">+</span> <span class="n">param_string</span> <span class="o">+</span> <span class="s">".nc"</span><span class="p">,</span>
    <span class="p">})</span>
</code></pre></div></div>

<p>I learnt the above steps on these pages:</p>
<ul>
  <li><a href="https://software.ecmwf.int/wiki/display/WEBAPI/Access+ECMWF+Public+Datasets#AccessECMWFPublicDatasets-python">ECMWF python library</a></li>
  <li><a href="https://pypi.python.org/pypi/setuptools">Python setuptool</a></li>
</ul>

        </div>
        <label for="/2018/02/23/ECMWF-download/" class="read-more-trigger"></label>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2018/01/27/resources-for-deeplearning/">
        Resources on deep learning
      </a>
    </h1>

    <span class="post-date">27 Jan 2018</span>

    
        <p>I have been searching for solutions how to use Recurrent Neural Networks for text classifications. Here are some useful resources I’ve found:</p>
<ul>
  <li><a href="https://www.deepdetect.com/">Open Source Deep Learning Server</a> has a library of <a href="https://www.deepdetect.com/applications/text_model/">pre-trained neural nets</a>.</li>
  <li>An <a href="https://www.analyticsvidhya.com/blog/2017/06/transfer-learning-the-art-of-fine-tuning-a-pre-trained-model/">article on Analytics Vidhya</a> 
discuss about transfer learning &amp; The art of using pre-trained models in deep learning. They also have <a href="https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/">an article about word embeddings</a>.</li>
  <li>Keras has a list of <a href="https://keras.io/applications/#usage-examples-for-image-classification-models">deep learning models with pre-trained weights</a>.</li>
  <li><a href="http://hyperopt.github.io/hyperopt/">Hyperopt</a> is a python library for Distributed Asynchronous Hyperparameter Optimization.</li>
  <li><a href="http://shop.oreilly.com/product/0636920052289.do">Hands-On Machine Learning with Scikit-Learn and TensorFlow</a> has discussion on deep learning from Ch.10 onward.</li>
  <li>Kaggle forum has a beginner tutorial of <a href="https://www.kaggle.com/sbongo/for-beginners-tackling-toxic-using-keras/notebook">using RNN to classify toxic comments</a> on wikipedia editing page.<br />
(To be updated.)</li>
</ul>


    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2018/01/23/Publications-updated/">
        Three co-authored papers submitted
      </a>
    </h1>

    <span class="post-date">23 Jan 2018</span>

    
        <p>The <a href="/publications/">publication page</a> 
has been updated with 3 submitted manuscripts.</p>

<p>Updates on Feb 9, 2018: The manuscript “Role of Finite-Amplitude Rossby Waves and Nonconservative 
Processes in Downward Migration of Extratropical Flow Anomalies” has been accepted by <em>Journal of Atmospheric Sciences</em>.</p>

<p>The subroutine 
<code class="language-plaintext highlighter-rouge">wrapper.qgpv_eqlat_lwa_ncforce</code> for computing effective diffusivity, which quantifies the 
damping on wave transiences by irreversible mixing in the stratosphere during a 
stratospheric sudden warming event, can be found in <a href="http://hn2016-falwa.readthedocs.io/en/latest/Wrapper%20Functions.html">my python package</a>.</p>

    
  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/page3">Older</a>
  
  
    
      <a class="pagination-item newer" href="/">Newer</a>
    
  
</div>

<div>
<p><!-- hitwebcounter Code START -->
<a href="http://www.hitwebcounter.com" target="_blank">
<img src="http://hitwebcounter.com/counter/counter.php?page=6563193&style=0006&nbdigits=5&type=page&initCount=0" title="my widget for counting" Alt="my widget for counting (since Dec24, 2016)"   border="0" >
</a> <br/>
</p>
</div>
  <link rel="stylesheet" href="/public/css/trial.css">

      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', function(e) {
          var target = e.target;

          if(!checkbox.checked ||
             sidebar.contains(target) ||
             (target === checkbox || target === toggle)) return;

          checkbox.checked = false;
        }, false);
      })(document);
    </script>
  </body>
</html>
